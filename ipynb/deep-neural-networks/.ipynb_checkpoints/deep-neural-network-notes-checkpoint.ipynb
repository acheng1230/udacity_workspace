{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_height = 32\n",
    "input_width = 32\n",
    "input_depth = 3\n",
    "\n",
    "filter_height = 8\n",
    "filter_width = 8\n",
    "filters = 20\n",
    "\n",
    "S = 2\n",
    "P = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.0\n",
      "14.0\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "new_height = (input_height - filter_height + 2 * P)/S + 1\n",
    "new_width = (input_width - filter_width + 2 * P)/S + 1\n",
    "depth = filters\n",
    "\n",
    "print(new_height)\n",
    "print(new_width)\n",
    "print(depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output depth \n",
    "k_output = 64\n",
    "\n",
    "# Image properties\n",
    "image_width = 10\n",
    "image_height = 10\n",
    "color_channels = 3\n",
    "\n",
    "# Convolution filter\n",
    "filter_size_width = 5\n",
    "filter_size_height = 5\n",
    "\n",
    "# Input/Image\n",
    "input = tf.placeholder(\n",
    "            tf.float32, \n",
    "            shape=[None, image_height, image_width, color_channels])\n",
    "\n",
    "# Weight and bias\n",
    "weight = tf.Variable(tf.truncated_normal(\n",
    "            [filter_size_height, filter_size_width, color_channels, k_output]))\n",
    "bias = tf.Variable(tf.zeros(k_output))\n",
    "\n",
    "# Apply Convolution\n",
    "conv_layer = tf.nn.conv2d(input, weight, strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "# Add bias\n",
    "conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "\n",
    "# Apply activation_function\n",
    "conv_layer = tf.nn.relu(conv_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Max Pooling\n",
    "\n",
    "For example, [[1, 0], [4, 6]] becomes 6, because 6 is the maximum value in this set. Similarly, [[2, 3], [6, 8]] becomes 8.\n",
    "\n",
    "Conceptually, the benefit of the max pooling operation is to reduce the size of the input, and allow the neural network to focus on only the most important elements. Max pooling does this by only retaining the maximum value for each filtered area, and removing the remaining values.\n",
    "\n",
    "TensorFlow provides the tf.nn.max_pool() function to apply max pooling to your convolutional layers.\n",
    "\n",
    "The tf.nn.max_pool() function performs max pooling with the ksize parameter as the size of the filter and the strides parameter as the length of the stride. 2x2 filters with a stride of 2x2 are common in practice.\n",
    "\n",
    "The ksize and strides parameters are structured as 4-element lists, with each element corresponding to a dimension of the input tensor ([batch, height, width, channels]). For both ksize and strides, the batch and channel dimensions are typically set to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_layer = tf.nn.conv2d(input, weight, strides=[1,2,2,1], padding='SAME')\n",
    "conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "conv_layer = tf.nn.relu(conv_layer)\n",
    "\n",
    "# Apply Max Pooling\n",
    "conv_layer = tf.nn.max_pool(\n",
    "                conv_layer,\n",
    "                ksize=[1,2,2,1],\n",
    "                strides=[1,2,2,1],\n",
    "                padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz\n",
    "\n",
    "A pooling layer is generally used to **decrease the size of the output** and **prevent overfitting**. Preventing overfitting is a consequence of reducing the output size, which in turn, reduces the number of parameters in future layers.\n",
    "\n",
    "Recently pooling layers have fallen out of favor. Some reasons why:\n",
    "- Recent datasets are so big and complex we're more concerned about underfitting\n",
    "- Dropout is a much better regularizer\n",
    "- Pooling results in a loss of information. Think about the max pooling operation as an example. We only keep the largest of n numbers, thereby disregarding n-1 numbers entirely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz: Pooling Mechanics\n",
    "\n",
    "What's the shape of the output? Depth stays the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = tf.placeholder(tf.float32, (None, 4, 4, 5))\n",
    "filter_shape = [1,2,2,1]\n",
    "strides = [1,2,2,1]\n",
    "padding = 'VALID'\n",
    "pool = tf.nn.max_pool(input, filter_shape, strides, padding)\n",
    "\n",
    "# output shape of pool will be [1,2,2,5], \n",
    "# even if padding is changed to SAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Network in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.00001\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Number of samples to calculate validation and accuracy\n",
    "# Decrease this if you're running out of memory to calculate accuracy\n",
    "test_valid_size = 256\n",
    "\n",
    "# Network parameters\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75 # Dropout, probabilty to keep units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store layers weights and bias\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5,5,1,32])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5,5,32,64])),\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutions\n",
    "\n",
    "The below image is an example of a convolution with a 3x3 filter and a stride of 1 being applied to data with a range of 0 to 1. The convolution for each 3x3 section is calculated against the weight, [[1, 0, 1], [0, 1, 0], [1, 0, 1]], then a bias is added to create the convolved feature on the right. In this case, the bias is zero. In TensorFlow, this is all done using tf.nn.conv2d() and tf.nn.bias_add().\n",
    "\n",
    "![Convolution Schematic](../../images/convolution-schematic.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Max Pooling\n",
    "\n",
    "The above is an example of max pooling with a 2x2 filter and stride of 2. The left square is the input and the right square is the output. The four 2x2 colors in input represents each time the filter was applied to create the max on the right side. For example, [[1, 1], [5, 6]] becomes 6 and [[3, 2], [1, 2]] becomes 3.\n",
    "\n",
    "![Max Pooling](../../images/maxpool.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(\n",
    "        x,\n",
    "        ksize=[1,k,k,1],\n",
    "        strides=[1,k,k,1],\n",
    "        padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Model\n",
    "\n",
    "In the code below, we're creating 3 layers alternating between convolutions and max pooling followed by a fully connected and output layer. The transformation of each layer to new dimensions are shown in the comments. For example, the first layer shapes the images from 28x28x1 to 28x28x32 in the convolution step. Then next step applies max pooling, turning each sample into 14x14x32. All the layers are applied from conv1 to output, producing 10 class predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Layer 1 - 28*28*1 to 14*14*32\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "    \n",
    "    # Layer 2 - 14*14*32 to 7*7*64\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "    \n",
    "    # Fully connected layer - 7*7*64 to 1024\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "    \n",
    "    # Output Layer - class prediction - 1024 to 10\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch   1 -Loss: 70383.7031 Validation Accuracy: 0.132812\n",
      "Epoch  1, Batch   2 -Loss: 47495.0312 Validation Accuracy: 0.136719\n",
      "Epoch  1, Batch   3 -Loss: 45145.0859 Validation Accuracy: 0.125000\n",
      "Epoch  1, Batch   4 -Loss: 33284.1602 Validation Accuracy: 0.128906\n",
      "Epoch  1, Batch   5 -Loss: 34799.7266 Validation Accuracy: 0.105469\n",
      "Epoch  1, Batch   6 -Loss: 27335.7617 Validation Accuracy: 0.105469\n",
      "Epoch  1, Batch   7 -Loss: 25503.1445 Validation Accuracy: 0.117188\n",
      "Epoch  1, Batch   8 -Loss: 26931.9180 Validation Accuracy: 0.109375\n",
      "Epoch  1, Batch   9 -Loss: 26084.5273 Validation Accuracy: 0.125000\n",
      "Epoch  1, Batch  10 -Loss: 20951.3086 Validation Accuracy: 0.113281\n",
      "Epoch  1, Batch  11 -Loss: 19290.6211 Validation Accuracy: 0.113281\n",
      "Epoch  1, Batch  12 -Loss: 23549.4688 Validation Accuracy: 0.113281\n",
      "Epoch  1, Batch  13 -Loss: 21264.7031 Validation Accuracy: 0.136719\n",
      "Epoch  1, Batch  14 -Loss: 19929.8047 Validation Accuracy: 0.128906\n",
      "Epoch  1, Batch  15 -Loss: 17604.9844 Validation Accuracy: 0.148438\n",
      "Epoch  1, Batch  16 -Loss: 19224.9727 Validation Accuracy: 0.128906\n",
      "Epoch  1, Batch  17 -Loss: 20985.9141 Validation Accuracy: 0.152344\n",
      "Epoch  1, Batch  18 -Loss: 16843.1680 Validation Accuracy: 0.175781\n",
      "Epoch  1, Batch  19 -Loss: 16596.2344 Validation Accuracy: 0.175781\n",
      "Epoch  1, Batch  20 -Loss: 15737.4141 Validation Accuracy: 0.191406\n",
      "Epoch  1, Batch  21 -Loss: 16487.0918 Validation Accuracy: 0.199219\n",
      "Epoch  1, Batch  22 -Loss: 16851.5547 Validation Accuracy: 0.226562\n",
      "Epoch  1, Batch  23 -Loss: 19382.3594 Validation Accuracy: 0.199219\n",
      "Epoch  1, Batch  24 -Loss: 17447.8867 Validation Accuracy: 0.210938\n",
      "Epoch  1, Batch  25 -Loss: 15709.2988 Validation Accuracy: 0.214844\n",
      "Epoch  1, Batch  26 -Loss: 17270.7617 Validation Accuracy: 0.226562\n",
      "Epoch  1, Batch  27 -Loss: 13332.8359 Validation Accuracy: 0.242188\n",
      "Epoch  1, Batch  28 -Loss: 14941.3008 Validation Accuracy: 0.250000\n",
      "Epoch  1, Batch  29 -Loss: 16472.4414 Validation Accuracy: 0.234375\n",
      "Epoch  1, Batch  30 -Loss: 14192.5957 Validation Accuracy: 0.234375\n",
      "Epoch  1, Batch  31 -Loss: 12602.0391 Validation Accuracy: 0.265625\n",
      "Epoch  1, Batch  32 -Loss: 12488.5703 Validation Accuracy: 0.261719\n",
      "Epoch  1, Batch  33 -Loss:  9681.4463 Validation Accuracy: 0.261719\n",
      "Epoch  1, Batch  34 -Loss: 11038.4688 Validation Accuracy: 0.277344\n",
      "Epoch  1, Batch  35 -Loss: 12734.6895 Validation Accuracy: 0.285156\n",
      "Epoch  1, Batch  36 -Loss: 14090.2158 Validation Accuracy: 0.308594\n",
      "Epoch  1, Batch  37 -Loss: 11276.8174 Validation Accuracy: 0.304688\n",
      "Epoch  1, Batch  38 -Loss: 10100.9707 Validation Accuracy: 0.292969\n",
      "Epoch  1, Batch  39 -Loss: 10092.9434 Validation Accuracy: 0.304688\n",
      "Epoch  1, Batch  40 -Loss:  9162.1797 Validation Accuracy: 0.308594\n",
      "Epoch  1, Batch  41 -Loss: 11526.5010 Validation Accuracy: 0.359375\n",
      "Epoch  1, Batch  42 -Loss: 11137.9004 Validation Accuracy: 0.347656\n",
      "Epoch  1, Batch  43 -Loss:  8232.7871 Validation Accuracy: 0.347656\n",
      "Epoch  1, Batch  44 -Loss:  8794.8438 Validation Accuracy: 0.351562\n",
      "Epoch  1, Batch  45 -Loss: 10234.5449 Validation Accuracy: 0.351562\n",
      "Epoch  1, Batch  46 -Loss:  7751.6865 Validation Accuracy: 0.359375\n",
      "Epoch  1, Batch  47 -Loss:  9064.8652 Validation Accuracy: 0.359375\n",
      "Epoch  1, Batch  48 -Loss:  7762.2422 Validation Accuracy: 0.347656\n",
      "Epoch  1, Batch  49 -Loss: 11538.6416 Validation Accuracy: 0.363281\n",
      "Epoch  1, Batch  50 -Loss:  7722.6504 Validation Accuracy: 0.378906\n",
      "Epoch  1, Batch  51 -Loss:  7574.2168 Validation Accuracy: 0.359375\n",
      "Epoch  1, Batch  52 -Loss: 10544.8633 Validation Accuracy: 0.371094\n",
      "Epoch  1, Batch  53 -Loss: 10632.1855 Validation Accuracy: 0.382812\n",
      "Epoch  1, Batch  54 -Loss:  7378.4189 Validation Accuracy: 0.390625\n",
      "Epoch  1, Batch  55 -Loss:  8351.6377 Validation Accuracy: 0.398438\n",
      "Epoch  1, Batch  56 -Loss:  6201.9209 Validation Accuracy: 0.375000\n",
      "Epoch  1, Batch  57 -Loss:  9354.2588 Validation Accuracy: 0.398438\n",
      "Epoch  1, Batch  58 -Loss:  9439.7119 Validation Accuracy: 0.414062\n",
      "Epoch  1, Batch  59 -Loss: 10390.0801 Validation Accuracy: 0.437500\n",
      "Epoch  1, Batch  60 -Loss:  9714.2510 Validation Accuracy: 0.417969\n",
      "Epoch  1, Batch  61 -Loss:  8158.2656 Validation Accuracy: 0.421875\n",
      "Epoch  1, Batch  62 -Loss:  7441.7051 Validation Accuracy: 0.414062\n",
      "Epoch  1, Batch  63 -Loss:  8512.0352 Validation Accuracy: 0.406250\n",
      "Epoch  1, Batch  64 -Loss:  8925.0459 Validation Accuracy: 0.414062\n",
      "Epoch  1, Batch  65 -Loss:  7410.6680 Validation Accuracy: 0.421875\n",
      "Epoch  1, Batch  66 -Loss:  7842.2612 Validation Accuracy: 0.406250\n",
      "Epoch  1, Batch  67 -Loss:  8135.6689 Validation Accuracy: 0.414062\n",
      "Epoch  1, Batch  68 -Loss:  6677.0859 Validation Accuracy: 0.425781\n",
      "Epoch  1, Batch  69 -Loss:  7457.0435 Validation Accuracy: 0.429688\n",
      "Epoch  1, Batch  70 -Loss:  8060.8872 Validation Accuracy: 0.445312\n",
      "Epoch  1, Batch  71 -Loss:  8191.4507 Validation Accuracy: 0.449219\n",
      "Epoch  1, Batch  72 -Loss:  9301.0928 Validation Accuracy: 0.445312\n",
      "Epoch  1, Batch  73 -Loss:  8571.4189 Validation Accuracy: 0.437500\n",
      "Epoch  1, Batch  74 -Loss:  7058.4375 Validation Accuracy: 0.441406\n",
      "Epoch  1, Batch  75 -Loss:  6216.3569 Validation Accuracy: 0.453125\n",
      "Epoch  1, Batch  76 -Loss:  9229.4941 Validation Accuracy: 0.457031\n",
      "Epoch  1, Batch  77 -Loss: 11200.6250 Validation Accuracy: 0.460938\n",
      "Epoch  1, Batch  78 -Loss:  6200.4082 Validation Accuracy: 0.460938\n",
      "Epoch  1, Batch  79 -Loss:  4634.2100 Validation Accuracy: 0.453125\n",
      "Epoch  1, Batch  80 -Loss:  6271.4248 Validation Accuracy: 0.460938\n",
      "Epoch  1, Batch  81 -Loss:  4979.2319 Validation Accuracy: 0.464844\n",
      "Epoch  1, Batch  82 -Loss:  5541.2383 Validation Accuracy: 0.468750\n",
      "Epoch  1, Batch  83 -Loss:  5836.3618 Validation Accuracy: 0.464844\n",
      "Epoch  1, Batch  84 -Loss:  6077.4873 Validation Accuracy: 0.460938\n",
      "Epoch  1, Batch  85 -Loss:  7513.5068 Validation Accuracy: 0.484375\n",
      "Epoch  1, Batch  86 -Loss:  4938.5967 Validation Accuracy: 0.484375\n",
      "Epoch  1, Batch  87 -Loss:  6164.9922 Validation Accuracy: 0.472656\n",
      "Epoch  1, Batch  88 -Loss:  5349.8926 Validation Accuracy: 0.492188\n",
      "Epoch  1, Batch  89 -Loss:  5716.0146 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch  90 -Loss:  4039.3245 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch  91 -Loss:  4380.0723 Validation Accuracy: 0.511719\n",
      "Epoch  1, Batch  92 -Loss:  4064.0669 Validation Accuracy: 0.503906\n",
      "Epoch  1, Batch  93 -Loss:  6535.5625 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch  94 -Loss:  4903.0859 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch  95 -Loss:  4815.0732 Validation Accuracy: 0.488281\n",
      "Epoch  1, Batch  96 -Loss:  5983.4551 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch  97 -Loss:  6455.2266 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch  98 -Loss:  6226.8467 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch  99 -Loss:  4425.8398 Validation Accuracy: 0.503906\n",
      "Epoch  1, Batch 100 -Loss:  5628.1465 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch 101 -Loss:  4467.3823 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch 102 -Loss:  4643.4521 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch 103 -Loss:  4748.5088 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch 104 -Loss:  5031.5449 Validation Accuracy: 0.511719\n",
      "Epoch  1, Batch 105 -Loss:  4983.0527 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch 106 -Loss:  5624.2651 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch 107 -Loss:  4666.4863 Validation Accuracy: 0.511719\n",
      "Epoch  1, Batch 108 -Loss:  3773.8188 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch 109 -Loss:  3014.6414 Validation Accuracy: 0.531250\n",
      "Epoch  1, Batch 110 -Loss:  4245.8774 Validation Accuracy: 0.535156\n",
      "Epoch  1, Batch 111 -Loss:  5752.8330 Validation Accuracy: 0.531250\n",
      "Epoch  1, Batch 112 -Loss:  4210.3813 Validation Accuracy: 0.535156\n",
      "Epoch  1, Batch 113 -Loss:  4684.2686 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch 114 -Loss:  3770.7866 Validation Accuracy: 0.542969\n",
      "Epoch  1, Batch 115 -Loss:  3045.0540 Validation Accuracy: 0.539062\n",
      "Epoch  1, Batch 116 -Loss:  3859.2898 Validation Accuracy: 0.535156\n",
      "Epoch  1, Batch 117 -Loss:  4250.3633 Validation Accuracy: 0.527344\n",
      "Epoch  1, Batch 118 -Loss:  6142.2515 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch 119 -Loss:  4012.9331 Validation Accuracy: 0.535156\n",
      "Epoch  1, Batch 120 -Loss:  4696.3491 Validation Accuracy: 0.539062\n",
      "Epoch  1, Batch 121 -Loss:  3170.9617 Validation Accuracy: 0.546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 122 -Loss:  3692.6245 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch 123 -Loss:  2812.0347 Validation Accuracy: 0.535156\n",
      "Epoch  1, Batch 124 -Loss:  4185.3364 Validation Accuracy: 0.535156\n",
      "Epoch  1, Batch 125 -Loss:  3580.7786 Validation Accuracy: 0.535156\n",
      "Epoch  1, Batch 126 -Loss:  3885.9102 Validation Accuracy: 0.539062\n",
      "Epoch  1, Batch 127 -Loss:  4035.4502 Validation Accuracy: 0.539062\n",
      "Epoch  1, Batch 128 -Loss:  4018.4338 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch 129 -Loss:  4678.0205 Validation Accuracy: 0.542969\n",
      "Epoch  1, Batch 130 -Loss:  3532.1892 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch 131 -Loss:  3485.4983 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch 132 -Loss:  3622.1284 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch 133 -Loss:  2961.4736 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch 134 -Loss:  5066.0713 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch 135 -Loss:  4789.9375 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch 136 -Loss:  3408.2485 Validation Accuracy: 0.542969\n",
      "Epoch  1, Batch 137 -Loss:  4271.4604 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch 138 -Loss:  4065.2090 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch 139 -Loss:  3463.8672 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch 140 -Loss:  4249.8979 Validation Accuracy: 0.570312\n",
      "Epoch  1, Batch 141 -Loss:  3170.5444 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 142 -Loss:  3459.5088 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 143 -Loss:  2154.7178 Validation Accuracy: 0.570312\n",
      "Epoch  1, Batch 144 -Loss:  3239.6653 Validation Accuracy: 0.570312\n",
      "Epoch  1, Batch 145 -Loss:  4103.1826 Validation Accuracy: 0.570312\n",
      "Epoch  1, Batch 146 -Loss:  4205.5195 Validation Accuracy: 0.570312\n",
      "Epoch  1, Batch 147 -Loss:  3950.3926 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch 148 -Loss:  4005.5635 Validation Accuracy: 0.570312\n",
      "Epoch  1, Batch 149 -Loss:  3273.0542 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 150 -Loss:  2728.6116 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 151 -Loss:  4000.8208 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 152 -Loss:  2244.1064 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 153 -Loss:  3432.2659 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 154 -Loss:  2745.5840 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 155 -Loss:  3408.7593 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 156 -Loss:  3478.8435 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 157 -Loss:  3411.0801 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 158 -Loss:  2507.9075 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 159 -Loss:  3531.4912 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 160 -Loss:  2583.0703 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch 161 -Loss:  2584.8748 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch 162 -Loss:  3006.9507 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 163 -Loss:  4084.6584 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 164 -Loss:  3364.4111 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 165 -Loss:  2883.8369 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 166 -Loss:  2844.5820 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 167 -Loss:  2719.8950 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 168 -Loss:  4157.0620 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 169 -Loss:  4191.1118 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 170 -Loss:  3049.4370 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 171 -Loss:  2781.0767 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 172 -Loss:  2720.6035 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 173 -Loss:  2967.2522 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 174 -Loss:  3181.4438 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 175 -Loss:  2346.1641 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 176 -Loss:  3925.8025 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 177 -Loss:  2503.7437 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 178 -Loss:  3340.0273 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 179 -Loss:  2390.5095 Validation Accuracy: 0.570312\n",
      "Epoch  1, Batch 180 -Loss:  2176.1694 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 181 -Loss:  2465.1748 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 182 -Loss:  2783.3342 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 183 -Loss:  3600.9058 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 184 -Loss:  1726.2732 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 185 -Loss:  3869.6101 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 186 -Loss:  2872.0598 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 187 -Loss:  2974.3696 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 188 -Loss:  3221.6628 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 189 -Loss:  2931.1653 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 190 -Loss:  3452.0986 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 191 -Loss:  2550.0210 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 192 -Loss:  2778.0732 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 193 -Loss:  2387.6802 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 194 -Loss:  2315.2454 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 195 -Loss:  3832.4641 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 196 -Loss:  4102.0537 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 197 -Loss:  3339.3086 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 198 -Loss:  2932.7349 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 199 -Loss:  3114.8645 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 200 -Loss:  2757.6992 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 201 -Loss:  2939.4001 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 202 -Loss:  3252.1667 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 203 -Loss:  2848.5376 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 204 -Loss:  2983.1206 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 205 -Loss:  2774.6877 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 206 -Loss:  3453.9233 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 207 -Loss:  3146.4805 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 208 -Loss:  2208.1917 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 209 -Loss:  3634.1521 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 210 -Loss:  2942.2212 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 211 -Loss:  2482.9976 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 212 -Loss:  2851.9751 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 213 -Loss:  2817.5498 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 214 -Loss:  3630.7175 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 215 -Loss:  3461.3608 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 216 -Loss:  2234.3706 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 217 -Loss:  2524.4612 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 218 -Loss:  2765.3608 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 219 -Loss:  2429.0940 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 220 -Loss:  2281.6411 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 221 -Loss:  2225.0986 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 222 -Loss:  1849.6929 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 223 -Loss:  2357.3643 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 224 -Loss:  2181.1233 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 225 -Loss:  2368.0654 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 226 -Loss:  1552.0984 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 227 -Loss:  1817.5630 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 228 -Loss:  2144.7844 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 229 -Loss:  1888.1150 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 230 -Loss:  2535.8193 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 231 -Loss:  2693.7971 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 232 -Loss:  2445.1191 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 233 -Loss:  2711.6709 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 234 -Loss:  2814.9617 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 235 -Loss:  2231.2878 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 236 -Loss:  2113.1365 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 237 -Loss:  2275.0479 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 238 -Loss:  1591.1213 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 239 -Loss:  2033.1609 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 240 -Loss:  2632.9409 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 241 -Loss:  2211.5322 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 242 -Loss:  2245.9819 Validation Accuracy: 0.621094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 243 -Loss:  2933.9141 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 244 -Loss:  2378.7000 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 245 -Loss:  1907.7283 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 246 -Loss:  2326.6643 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 247 -Loss:  2575.4185 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 248 -Loss:  1818.3962 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 249 -Loss:  2419.4185 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 250 -Loss:  2229.0881 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 251 -Loss:  2549.6560 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 252 -Loss:  1496.5273 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 253 -Loss:  2206.2734 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 254 -Loss:  2417.6567 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 255 -Loss:  1826.3560 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 256 -Loss:  1974.5726 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 257 -Loss:  2425.7402 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 258 -Loss:  2592.2485 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 259 -Loss:  2272.6587 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 260 -Loss:  1781.1858 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 261 -Loss:  1870.6372 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 262 -Loss:  1738.4346 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 263 -Loss:  2501.0493 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 264 -Loss:  1565.9996 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 265 -Loss:  1716.3474 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 266 -Loss:  1789.0398 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 267 -Loss:  1416.1688 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 268 -Loss:  2086.1099 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 269 -Loss:  2068.1340 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 270 -Loss:  2177.2202 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 271 -Loss:  2096.5098 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 272 -Loss:  2459.9824 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 273 -Loss:  1955.8347 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 274 -Loss:  1768.0542 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 275 -Loss:  1967.0588 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 276 -Loss:  1901.3254 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 277 -Loss:  1422.4484 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 278 -Loss:  2383.6323 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 279 -Loss:  2179.0320 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 280 -Loss:  1955.7014 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 281 -Loss:  1318.5017 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 282 -Loss:  2117.2673 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 283 -Loss:  1997.2728 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 284 -Loss:  2785.0894 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 285 -Loss:  2897.0244 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 286 -Loss:  2000.7563 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 287 -Loss:  1606.4536 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 288 -Loss:  1711.2080 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 289 -Loss:  1799.3986 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 290 -Loss:  2063.0859 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 291 -Loss:  1987.6567 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 292 -Loss:  2133.2505 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 293 -Loss:  1797.3267 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 294 -Loss:  1597.5264 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 295 -Loss:  2451.0774 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 296 -Loss:  1629.3156 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 297 -Loss:  2395.8955 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 298 -Loss:  2325.0286 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 299 -Loss:  1548.7898 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 300 -Loss:  1704.4332 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 301 -Loss:  1430.8315 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 302 -Loss:  1540.3713 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 303 -Loss:  1586.7896 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 304 -Loss:  1966.9087 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 305 -Loss:  1827.2437 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 306 -Loss:  1811.0908 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 307 -Loss:  1580.6514 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 308 -Loss:  1843.3088 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 309 -Loss:  1315.5613 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 310 -Loss:  1543.8994 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 311 -Loss:  1905.4680 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 312 -Loss:  1710.2643 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 313 -Loss:  1918.1746 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 314 -Loss:  2043.4279 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 315 -Loss:   929.9290 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 316 -Loss:  2184.3743 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 317 -Loss:  2133.1084 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 318 -Loss:  1796.1307 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 319 -Loss:  2113.7747 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 320 -Loss:  1404.0276 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 321 -Loss:  1520.2566 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 322 -Loss:  1537.3311 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 323 -Loss:  1872.6042 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 324 -Loss:  1916.4036 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 325 -Loss:  1669.2344 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 326 -Loss:  1622.7039 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 327 -Loss:  1073.1223 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 328 -Loss:  1429.6666 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 329 -Loss:  1248.2976 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 330 -Loss:  1433.0222 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 331 -Loss:  1642.2319 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 332 -Loss:  1703.5706 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 333 -Loss:  1952.3086 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 334 -Loss:  1648.0887 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 335 -Loss:  1502.6909 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 336 -Loss:  2259.8838 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 337 -Loss:  1576.7206 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 338 -Loss:  1070.4612 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 339 -Loss:  1620.9249 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 340 -Loss:  1350.6498 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 341 -Loss:  1562.7778 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 342 -Loss:  1276.0510 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 343 -Loss:  1050.1143 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 344 -Loss:  2311.0547 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 345 -Loss:  2248.7432 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 346 -Loss:  1695.0751 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 347 -Loss:  1533.3193 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 348 -Loss:  2398.0156 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 349 -Loss:  2681.7720 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 350 -Loss:  1994.5771 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 351 -Loss:  2246.8420 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 352 -Loss:  2099.7681 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 353 -Loss:  1478.3171 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 354 -Loss:  1475.2139 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 355 -Loss:  2266.6631 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 356 -Loss:  1916.8801 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 357 -Loss:  2086.5671 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 358 -Loss:  1406.7461 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 359 -Loss:  1170.2216 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 360 -Loss:  1252.8165 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 361 -Loss:  1455.9860 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 362 -Loss:  2076.9314 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 363 -Loss:  1311.1953 Validation Accuracy: 0.683594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 364 -Loss:  1304.9849 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 365 -Loss:  1184.9409 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 366 -Loss:  1642.5149 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 367 -Loss:  1570.0530 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 368 -Loss:  1708.1843 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 369 -Loss:  1841.2926 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 370 -Loss:  1745.2644 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 371 -Loss:  1121.1674 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 372 -Loss:   897.1184 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 373 -Loss:  1487.1770 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 374 -Loss:  1328.4500 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 375 -Loss:  1818.7712 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 376 -Loss:  1648.5569 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 377 -Loss:  1382.7086 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 378 -Loss:  1288.9130 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 379 -Loss:  1120.9084 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 380 -Loss:  1721.0581 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 381 -Loss:  1241.9698 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 382 -Loss:  1148.8181 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 383 -Loss:  1080.4171 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 384 -Loss:  1586.5061 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 385 -Loss:  1283.7775 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 386 -Loss:  1408.0886 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 387 -Loss:  1271.6714 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 388 -Loss:  1259.6392 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 389 -Loss:  1286.6315 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 390 -Loss:  1683.6506 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 391 -Loss:  1651.6167 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 392 -Loss:  1121.4320 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 393 -Loss:  1177.7228 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 394 -Loss:  1380.5143 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 395 -Loss:  1269.2788 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 396 -Loss:  1200.4849 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 397 -Loss:   946.2056 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 398 -Loss:  1313.0308 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 399 -Loss:   774.5436 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 400 -Loss:  1442.0972 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 401 -Loss:  1104.3145 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 402 -Loss:  1280.0950 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 403 -Loss:  1688.5762 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 404 -Loss:  1230.0289 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 405 -Loss:  1371.0244 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 406 -Loss:  1216.9810 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 407 -Loss:  1535.2866 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 408 -Loss:  1002.8914 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 409 -Loss:  1954.8083 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 410 -Loss:  1193.5979 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 411 -Loss:  1473.6812 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 412 -Loss:  1851.1265 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 413 -Loss:  1230.8652 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 414 -Loss:  1141.2983 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 415 -Loss:  1268.7577 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 416 -Loss:   841.4773 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 417 -Loss:   768.8928 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 418 -Loss:   827.4176 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 419 -Loss:   727.3160 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 420 -Loss:   613.7982 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 421 -Loss:   767.1038 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 422 -Loss:   475.9816 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 423 -Loss:   560.3939 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 424 -Loss:   529.1270 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 425 -Loss:  2025.0950 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 426 -Loss:  1325.8105 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 427 -Loss:   780.8463 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 428 -Loss:  1151.9337 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 429 -Loss:   615.1740 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch   1 -Loss:  1106.2437 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch   2 -Loss:  1195.9706 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch   3 -Loss:  1553.4797 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch   4 -Loss:  1105.0208 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch   5 -Loss:  1322.1235 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch   6 -Loss:  1432.8956 Validation Accuracy: 0.691406\n",
      "Epoch  2, Batch   7 -Loss:  1125.3724 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch   8 -Loss:   670.2656 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch   9 -Loss:  1583.2332 Validation Accuracy: 0.691406\n",
      "Epoch  2, Batch  10 -Loss:  1114.7848 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  11 -Loss:  1384.8888 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch  12 -Loss:  1590.9950 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  13 -Loss:  1228.0333 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  14 -Loss:   985.7103 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch  15 -Loss:  1433.3950 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch  16 -Loss:  1283.2207 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch  17 -Loss:  1307.7577 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  18 -Loss:  1656.8276 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  19 -Loss:  1154.1478 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch  20 -Loss:  1593.4995 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch  21 -Loss:  1236.7725 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch  22 -Loss:  1242.2583 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  23 -Loss:   821.3528 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  24 -Loss:  1144.0420 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  25 -Loss:  1009.6622 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch  26 -Loss:  1079.2906 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  27 -Loss:  1388.9725 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  28 -Loss:  1109.2842 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  29 -Loss:  1323.7441 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  30 -Loss:  1632.3176 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch  31 -Loss:  1321.9484 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch  32 -Loss:  1597.6521 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  33 -Loss:   983.6160 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  34 -Loss:  1193.0173 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch  35 -Loss:  1071.0382 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch  36 -Loss:  1338.6277 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  37 -Loss:   750.4337 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  38 -Loss:  1328.4827 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  39 -Loss:  1079.8843 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  40 -Loss:  1067.0059 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  41 -Loss:  1437.3730 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  42 -Loss:   986.5827 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch  43 -Loss:  1349.2668 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch  44 -Loss:   683.3694 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch  45 -Loss:  1486.0010 Validation Accuracy: 0.691406\n",
      "Epoch  2, Batch  46 -Loss:  1336.3512 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch  47 -Loss:   990.9260 Validation Accuracy: 0.683594\n",
      "Epoch  2, Batch  48 -Loss:  1170.3057 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  49 -Loss:   897.2054 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch  50 -Loss:  1275.1987 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch  51 -Loss:  1094.5154 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  52 -Loss:  1205.0188 Validation Accuracy: 0.691406\n",
      "Epoch  2, Batch  53 -Loss:  1458.4526 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  54 -Loss:   984.9446 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch  55 -Loss:  1472.5176 Validation Accuracy: 0.707031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2, Batch  56 -Loss:  1241.9573 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch  57 -Loss:  1414.1719 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  58 -Loss:  1023.6103 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  59 -Loss:  1699.3174 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch  60 -Loss:  1261.1072 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch  61 -Loss:  1171.3643 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch  62 -Loss:  1626.8782 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch  63 -Loss:  1189.3060 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch  64 -Loss:   836.6609 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch  65 -Loss:   751.6805 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch  66 -Loss:  1132.6562 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  67 -Loss:  1121.0178 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  68 -Loss:  1524.5688 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  69 -Loss:  1319.1396 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch  70 -Loss:  1375.6423 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  71 -Loss:  1416.7134 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  72 -Loss:   998.7139 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  73 -Loss:  1147.8684 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  74 -Loss:  1497.1418 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  75 -Loss:  1132.2026 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  76 -Loss:   998.4802 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch  77 -Loss:  1149.5223 Validation Accuracy: 0.691406\n",
      "Epoch  2, Batch  78 -Loss:  1612.4056 Validation Accuracy: 0.691406\n",
      "Epoch  2, Batch  79 -Loss:  1138.0586 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  80 -Loss:  1290.0056 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch  81 -Loss:  1112.9717 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch  82 -Loss:   828.5530 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  83 -Loss:  1139.2520 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  84 -Loss:  1121.0685 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  85 -Loss:  1245.9261 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch  86 -Loss:   901.8446 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  87 -Loss:  1054.2756 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch  88 -Loss:   963.2133 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  89 -Loss:   999.9675 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch  90 -Loss:   729.8707 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  91 -Loss:  1034.3809 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch  92 -Loss:  1769.6130 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  93 -Loss:  1256.8752 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  94 -Loss:  1391.3265 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  95 -Loss:   810.5233 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch  96 -Loss:  1272.2881 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch  97 -Loss:  1466.5002 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch  98 -Loss:   892.1167 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch  99 -Loss:  1524.3678 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch 100 -Loss:  1388.0206 Validation Accuracy: 0.687500\n",
      "Epoch  2, Batch 101 -Loss:  1247.5713 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch 102 -Loss:   853.4976 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch 103 -Loss:  1469.0386 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch 104 -Loss:  1123.3419 Validation Accuracy: 0.695312\n",
      "Epoch  2, Batch 105 -Loss:  1119.0117 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch 106 -Loss:   933.4365 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch 107 -Loss:  1039.5966 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch 108 -Loss:   753.5838 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch 109 -Loss:   860.2424 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch 110 -Loss:   989.8543 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch 111 -Loss:  1206.9663 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch 112 -Loss:   967.6805 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch 113 -Loss:  1355.7545 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch 114 -Loss:  1155.7990 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 115 -Loss:  1677.2471 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 116 -Loss:   899.0999 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch 117 -Loss:  1494.8184 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 118 -Loss:  1120.0090 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch 119 -Loss:   629.4825 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 120 -Loss:  1033.0984 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 121 -Loss:  1187.5529 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 122 -Loss:  1204.9663 Validation Accuracy: 0.699219\n",
      "Epoch  2, Batch 123 -Loss:  1105.4225 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch 124 -Loss:   945.9806 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch 125 -Loss:   971.0122 Validation Accuracy: 0.703125\n",
      "Epoch  2, Batch 126 -Loss:   897.7975 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch 127 -Loss:  1097.9969 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch 128 -Loss:  1186.7484 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 129 -Loss:  1052.1913 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 130 -Loss:  1367.3147 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 131 -Loss:  1059.7329 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch 132 -Loss:  1380.4198 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 133 -Loss:  1130.2410 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 134 -Loss:  1179.0259 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch 135 -Loss:   761.5757 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 136 -Loss:   876.9612 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 137 -Loss:   977.3542 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 138 -Loss:   898.4553 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 139 -Loss:  1114.2308 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch 140 -Loss:  1373.5256 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch 141 -Loss:  1150.5050 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 142 -Loss:  1293.4502 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 143 -Loss:  1081.9426 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch 144 -Loss:   806.1862 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 145 -Loss:  1288.8530 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 146 -Loss:   628.2281 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 147 -Loss:  1274.9355 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 148 -Loss:   822.2442 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 149 -Loss:   841.4921 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch 150 -Loss:  1272.0908 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 151 -Loss:  1238.8013 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 152 -Loss:  1064.8986 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 153 -Loss:   874.0230 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 154 -Loss:  1540.3118 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 155 -Loss:  1006.9430 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch 156 -Loss:  1104.0872 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 157 -Loss:  1312.8574 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch 158 -Loss:  1121.0149 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 159 -Loss:  1346.6781 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch 160 -Loss:   716.0654 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 161 -Loss:  1175.1093 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 162 -Loss:   894.2571 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 163 -Loss:   982.2922 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 164 -Loss:   901.6875 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch 165 -Loss:  1324.5901 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 166 -Loss:  1142.2775 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 167 -Loss:   795.3975 Validation Accuracy: 0.707031\n",
      "Epoch  2, Batch 168 -Loss:  1023.3151 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 169 -Loss:   760.3906 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 170 -Loss:  1067.0599 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 171 -Loss:  1686.3845 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 172 -Loss:  1510.1399 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 173 -Loss:   943.6603 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 174 -Loss:   982.2719 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 175 -Loss:   673.1514 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 176 -Loss:   908.3124 Validation Accuracy: 0.722656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2, Batch 177 -Loss:   952.1319 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch 178 -Loss:  1544.2030 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 179 -Loss:   859.4064 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch 180 -Loss:  1037.1498 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 181 -Loss:  1279.6680 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 182 -Loss:   860.4595 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 183 -Loss:  1304.1333 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 184 -Loss:  1005.6945 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch 185 -Loss:  1207.7085 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 186 -Loss:  1071.0566 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 187 -Loss:  1066.8342 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 188 -Loss:  1027.6709 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 189 -Loss:  1193.0740 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 190 -Loss:  1295.7744 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch 191 -Loss:  1222.7090 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch 192 -Loss:   873.5002 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch 193 -Loss:  1485.6586 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 194 -Loss:   984.3748 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 195 -Loss:   952.0710 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 196 -Loss:   640.9371 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 197 -Loss:  1005.7417 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 198 -Loss:   562.4944 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 199 -Loss:  1153.1587 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 200 -Loss:  1004.6853 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 201 -Loss:   977.7114 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 202 -Loss:   685.2086 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 203 -Loss:   786.6046 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 204 -Loss:   789.9726 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 205 -Loss:   612.6165 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 206 -Loss:   993.0367 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 207 -Loss:   816.5380 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 208 -Loss:   864.7318 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 209 -Loss:   840.5881 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 210 -Loss:  1003.6556 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 211 -Loss:  1078.0714 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 212 -Loss:  1304.5432 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 213 -Loss:   765.9272 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 214 -Loss:   634.0768 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 215 -Loss:   887.7754 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch 216 -Loss:   876.0298 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch 217 -Loss:   749.3173 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch 218 -Loss:  1242.1111 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 219 -Loss:  1114.1870 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 220 -Loss:  1331.9510 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 221 -Loss:   947.0939 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 222 -Loss:   987.6581 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 223 -Loss:  1101.0433 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 224 -Loss:   996.5415 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch 225 -Loss:   818.9471 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 226 -Loss:   904.9741 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 227 -Loss:   720.2756 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 228 -Loss:  1415.6487 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 229 -Loss:  1020.4670 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 230 -Loss:   891.4191 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 231 -Loss:   930.7197 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch 232 -Loss:   720.9814 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 233 -Loss:  1337.3641 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 234 -Loss:   752.3199 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 235 -Loss:   933.5291 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 236 -Loss:   750.0458 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 237 -Loss:   779.2699 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 238 -Loss:   799.7791 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 239 -Loss:   742.5402 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 240 -Loss:   834.5244 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 241 -Loss:  1168.1572 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 242 -Loss:   885.3474 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 243 -Loss:  1026.7352 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 244 -Loss:   852.9291 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 245 -Loss:   898.1910 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 246 -Loss:  1004.1958 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 247 -Loss:   795.7942 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 248 -Loss:   960.6515 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 249 -Loss:   740.7465 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 250 -Loss:   812.4163 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 251 -Loss:  1008.3695 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 252 -Loss:   944.4471 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 253 -Loss:   816.1368 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 254 -Loss:   673.0493 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 255 -Loss:  1098.6527 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 256 -Loss:   599.4795 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 257 -Loss:   755.4375 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 258 -Loss:   587.6451 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 259 -Loss:   810.7219 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 260 -Loss:  1082.5405 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 261 -Loss:   947.5894 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 262 -Loss:  1019.7450 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 263 -Loss:   795.4449 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 264 -Loss:  1085.1698 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 265 -Loss:  1340.1368 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 266 -Loss:   743.7063 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 267 -Loss:   824.7988 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 268 -Loss:  1017.6311 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 269 -Loss:   823.5056 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch 270 -Loss:   842.0833 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 271 -Loss:   785.3500 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 272 -Loss:   824.5887 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 273 -Loss:   971.5331 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 274 -Loss:   828.4822 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 275 -Loss:   800.9360 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 276 -Loss:  1189.7427 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 277 -Loss:   873.3706 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 278 -Loss:   663.7389 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 279 -Loss:   759.0852 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 280 -Loss:   660.3801 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 281 -Loss:   776.7664 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 282 -Loss:   939.0001 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 283 -Loss:  1080.0142 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 284 -Loss:   800.8823 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 285 -Loss:   972.3350 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 286 -Loss:   643.8364 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 287 -Loss:   670.7632 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 288 -Loss:   904.8965 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 289 -Loss:   541.6375 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 290 -Loss:  1162.8424 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 291 -Loss:   881.2913 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 292 -Loss:   847.3160 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 293 -Loss:  1016.3926 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 294 -Loss:   606.5604 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 295 -Loss:   687.4665 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 296 -Loss:  1088.5864 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 297 -Loss:   815.2941 Validation Accuracy: 0.730469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2, Batch 298 -Loss:   736.3444 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 299 -Loss:  1216.5465 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 300 -Loss:  1042.5282 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 301 -Loss:   866.3604 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 302 -Loss:   751.1693 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 303 -Loss:   869.9495 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 304 -Loss:   909.0570 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 305 -Loss:  1046.4203 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 306 -Loss:   539.0296 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 307 -Loss:   916.9965 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 308 -Loss:   980.7732 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 309 -Loss:   881.2382 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 310 -Loss:   648.5325 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 311 -Loss:  1001.3302 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 312 -Loss:  1158.4950 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 313 -Loss:   850.6093 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 314 -Loss:  1230.1492 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 315 -Loss:   752.3616 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 316 -Loss:  1135.4744 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 317 -Loss:   896.4364 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 318 -Loss:  1074.7163 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 319 -Loss:  1026.7118 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 320 -Loss:  1217.7332 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 321 -Loss:  1238.4539 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 322 -Loss:   987.9367 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 323 -Loss:   920.4384 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 324 -Loss:   547.2054 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 325 -Loss:   598.3909 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 326 -Loss:   891.7188 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 327 -Loss:   980.4645 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 328 -Loss:  1152.7966 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 329 -Loss:   892.6982 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 330 -Loss:   834.1378 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 331 -Loss:   741.4711 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 332 -Loss:   860.4763 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 333 -Loss:   862.3721 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 334 -Loss:   835.2998 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 335 -Loss:   503.1111 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 336 -Loss:   666.0084 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 337 -Loss:   829.5958 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 338 -Loss:  1040.9364 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 339 -Loss:   860.7252 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 340 -Loss:   789.0391 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 341 -Loss:   712.0944 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 342 -Loss:  1127.8982 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 343 -Loss:   820.0938 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 344 -Loss:   858.3752 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 345 -Loss:   767.8800 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 346 -Loss:   881.2211 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 347 -Loss:   847.3110 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 348 -Loss:   833.8505 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 349 -Loss:   804.2021 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 350 -Loss:   652.7811 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 351 -Loss:   863.2010 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 352 -Loss:   589.7600 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 353 -Loss:  1072.2877 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 354 -Loss:  1014.2760 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 355 -Loss:  1095.3616 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 356 -Loss:   913.7708 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 357 -Loss:  1060.5446 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 358 -Loss:   783.0132 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 359 -Loss:   814.1469 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 360 -Loss:   702.2749 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 361 -Loss:   888.1365 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 362 -Loss:   802.0151 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 363 -Loss:   699.5806 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 364 -Loss:   848.4662 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 365 -Loss:   700.9058 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 366 -Loss:  1028.0314 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 367 -Loss:   608.5586 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 368 -Loss:   966.2759 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 369 -Loss:   588.2152 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 370 -Loss:   804.3127 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 371 -Loss:   649.7536 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 372 -Loss:   380.6114 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 373 -Loss:   689.5555 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 374 -Loss:   953.6286 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 375 -Loss:   544.5130 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 376 -Loss:   587.0117 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 377 -Loss:   505.8220 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 378 -Loss:   674.1852 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 379 -Loss:   862.8328 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 380 -Loss:   959.9429 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 381 -Loss:   655.4136 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 382 -Loss:   784.3744 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 383 -Loss:   832.8939 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 384 -Loss:   772.0623 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 385 -Loss:   982.2502 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 386 -Loss:   982.9916 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 387 -Loss:   574.1478 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 388 -Loss:   718.9626 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 389 -Loss:   854.1149 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 390 -Loss:   710.2142 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 391 -Loss:   997.1056 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 392 -Loss:   984.5891 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 393 -Loss:   653.6062 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 394 -Loss:   873.8026 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 395 -Loss:   964.2915 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 396 -Loss:  1049.8527 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 397 -Loss:   638.0137 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 398 -Loss:   608.5622 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 399 -Loss:   732.6303 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 400 -Loss:   719.8663 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 401 -Loss:   809.2638 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 402 -Loss:   560.0565 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 403 -Loss:   836.5486 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 404 -Loss:   624.5741 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 405 -Loss:   930.1494 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 406 -Loss:   868.4295 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 407 -Loss:   847.8479 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 408 -Loss:   931.8173 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 409 -Loss:   503.9903 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 410 -Loss:  1250.5067 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 411 -Loss:   673.9493 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 412 -Loss:   426.9851 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 413 -Loss:   867.0885 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 414 -Loss:   780.6094 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 415 -Loss:   878.7420 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 416 -Loss:   925.9182 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 417 -Loss:   557.3978 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 418 -Loss:   939.1686 Validation Accuracy: 0.769531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2, Batch 419 -Loss:   794.9905 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 420 -Loss:   710.1218 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 421 -Loss:   733.5637 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 422 -Loss:   660.5952 Validation Accuracy: 0.769531\n"
     ]
    }
   ],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "# Define the loss and optimizer\n",
    "cost = tf.reduce_mean(\\\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\\\n",
    "    .minimize(cost)\n",
    "    \n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(mnist.train.num_examples//batch_size):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optimizer, feed_dict={\n",
    "                x: batch_x, \n",
    "                y: batch_y,\n",
    "                keep_prob: dropout})\n",
    "            \n",
    "            # Calculate batch loss and accuracy\n",
    "            loss = sess.run(cost, feed_dict={\n",
    "                x: batch_x, \n",
    "                y: batch_y, \n",
    "                keep_prob: 1.})\n",
    "            valid_acc = sess.run(accuracy, feed_dict={\n",
    "                x: mnist.validation.images[:test_valid_size],\n",
    "                y: mnist.validation.labels[:test_valid_size],\n",
    "                keep_prob: 1.})\n",
    "            \n",
    "            print('Epoch {:>2}, Batch {:>3} -'\n",
    "                  'Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "                    epoch + 1, batch + 1, loss, valid_acc))\n",
    "            \n",
    "    # Calculate Test Accuracy\n",
    "    test_acc = sess.run(accuracy, feed_dict={\n",
    "        x: mnist.test.images[:test_valid_size],\n",
    "        y: mnist.test.labels[:test_valid_size],\n",
    "        keep_prob: 1.})\n",
    "    print('Testing Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
